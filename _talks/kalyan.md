--- 
key: kalyan
speaker: Kalyan Veeramachaneni
website: https://sites.google.com/view/jpei/jian-peis-homepage
affiliation: Massachusetts Institute of Technology
title: Towards Usable Machine Learning
time: 1:10pm - 2:10pm
picture: kalyan.jpg
picture-note: Kalyan Veeramachaneni
slides: 
bio: |
    Dr. Kalyan Veeramachaneni is a Principal Research Scientist at the Laboratory for Information and Decision System (LIDS) at MIT. He directs a research group called Data to AI in the new MIT Schwarzman College of Computing. His group focuses on building large-scale AI systems that work alongside humans, continuously learning from data, generating predictions and integrating those predictions into human decision-making. The group develops foundational algorithms, abstractions, and systems to enable these three tasks at scale. Algorithms, systems and open-source software developed by the group are deployed for applications in the financial, medical, and education sectors.   Kalyan was the co-founder of PatternEx (acq. by Corelight), a cybersecurity company that adapts machine learning models based on real-time analyst feedback. He was also the co-founder of FeatureLabs (acq. by Alteryx), a data science automation company. He is currently a co-founder of DataCebo which focuses on improving data access and availability through synthetic data generation. Kalyan has published over 70 publications and his work on AI-driven solutions for data science and cybersecurity has been covered by major media outlets, including the Washington Post, CBS News, Wired, Forbes and Newsweek. He received his Masters in Computer Engineering and Ph.D in Electrical Engineering in 2009, both from Syracuse University. He joined MIT in 2009. 

 
abstract: |
    We believe data science and AI will change the world.  No matter how smart and powerful AI models we can build, the ultimate testimony of the success of data science and AI is users' trust.  How can we build trustworthy data science?  At the level of user-model interaction, how can we convince users that a data analytic result is trustworthy?  In this talk, I will brainstorm possible directions to the above questions in the context of an end-to-end data science pipeline.  To strengthen trustworthy interactions between models and users, I will advocate exact and consistent interpretation of machine learning models.  Our recent results show that exact and consistent interpretations are not just theoretically feasible, but also practical even for API-based AI services.  Through reflection I will discuss some challenges and opportunities in building trustworthy data science for possible future work.
---