id,title,link,authors,abstract,type
1,PSEUDo: Interactive Pattern Search in Multivariate Time Series with Locality-Sensitive Hashing and Relevance Feedback,VDS-KDD_2022_paper_8514.pdf,"Yuncong Yu, Dylan Kruyff, Jiao Jiao, Tim Becker and Michael Behrisch","We present PSEUDo, a visual pattern retrieval tool for multivariate time series. It aims to overcome the uneconomic (re-)training problem accompanying deep learning-based methods. Very high-dimensional time series emerge on an unprecedented scale due to increasing sensor usage and data storage. Visual pattern search is one of the most frequent tasks on time series. Automatic pattern retrieval methods often suffer from inefficient training data, a lack of ground truth labels, and a discrepancy between the similarity perceived by the algorithm and required by the user or the task. Our proposal is based on the query-aware locality-sensitive hashing technique to create a representation of multivariate time series windows. It features sub-linear training and inference time with respect to data dimensions. This performance gain allows an instantaneous relevance-feedback-driven adaption to converge to users’ similarity notion. We demonstrate PSEUDo’s performance in terms of accuracy, speed, steerability, and usability through quantitative benchmarks with representative time series retrieval methods and a case study. We find that PSEUDo detects patterns in high-dimensional time series efficiently, improves the result with relevance feedback through feature selection, and allows an understandable as well as user-friendly retrieval process.",Paper
2,An Interpretable Neuron Embedding for Static Knowledge Distillation,VDS-KDD_2022_paper_5524.pdf,"Wei Han, Yangqiming Wang, Christian Boehm and Junming Shao","Although deep neural networks have shown well-performance in various tasks, the poor interpretability of the models is always criticized. In the paper, we propose a new interpretable neural network method, by embedding neurons into the semantic space to extract their intrinsic global semantics. In contrast to previous methods that probe latent knowledge inside the model, the proposed semantic vector externalizes the latent knowledge to static knowledge, which is easy to exploit. Specifically, we assume that neurons with similar activation are of similar semantic information. Afterwards, semantic vectors are optimized by continuously aligning activation similarity and semantic vector similarity during the training of the neural network. The visualization of semantic vectors allows for a qualitative explanation of the neural network. Moreover, we assess the static knowledge quantitatively by knowledge distillation tasks. Empirical experiments of visualization show that semantic vectors describe neuron activation semantics well. Without the sample-by-sample guidance from the teacher model, static knowledge distillation exhibit comparable or even superior performance with existing relation-based knowledge distillation methods.",Paper
3,PSEUDo: Interactive Pattern Search in Multivariate Time Series with Locality-Sensitive Hashing and Relevance Feedback, ,Yuncong Yu, ,Paper
4,Motif-Based Visual Analysis of Dynamic Networks, , Eren Cakmak, ,Paper
5,How Do Data Science Workers Communicate Intermediate Results?, , Yuren Pang, ,Paper
6,BiaScope: Visual Unfairness Diagnosis for Graph Embeddings, , Agapi Rissaki, ,Paper
7,Comparison of Computational Notebook Systems for Interactive Visual Analytics, , Han Liu, ,Paper
8,Interactive Visualization for Data Science Scripts , , Rebecca Faust, ,Paper
9,Communication Analysis through Visual Analytics: Current Practices, Challenges, and New Frontiers, , Maximilian T. Fischer , ,Paper



